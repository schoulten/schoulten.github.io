[
  {
    "objectID": "portfolio.html#forecasting",
    "href": "portfolio.html#forecasting",
    "title": "Fernando da Silva",
    "section": "Forecasting",
    "text": "Forecasting\n\n\nInflation — CPI\n\n\nMachine learning models for monthly forecasting of the main inflation index in Brazil.\n\n\nCode Details Application"
  },
  {
    "objectID": "portfolio.html#macroeconomics",
    "href": "portfolio.html#macroeconomics",
    "title": "Fernando da Silva",
    "section": "Macroeconomics",
    "text": "Macroeconomics\n\n\nMonetary policy transmission in Brazil\n\n\nEvaluation of the relationship between interest rates and economic activity over time using an IS curve (portuguese).\n\n\n Details"
  },
  {
    "objectID": "portfolio.html#econometricsml",
    "href": "portfolio.html#econometricsml",
    "title": "Fernando da Silva",
    "section": "Econometrics/ML",
    "text": "Econometrics/ML\n\n\nBias-variance trade off\n\n\nAn article with a simple explanation about these concepts applied to predictive models of time series (portuguese).\n\n\n Details"
  },
  {
    "objectID": "portfolio.html#dashboards",
    "href": "portfolio.html#dashboards",
    "title": "Fernando da Silva",
    "section": "Dashboards",
    "text": "Dashboards\n\n\nMacro View\n\n\nA dashboard on Brazilian macroeconomic data (economic activity, inflation, labor market, fiscal and monetary policy).\n\n\nCode Details Application\n\n\n\n\nMacro Copa\n\n\nA dashboard to compare macroeconomic indicators of the 2022 World Cup countries.\n\n\nCode Details Application"
  },
  {
    "objectID": "portfolio.html#software",
    "href": "portfolio.html#software",
    "title": "Fernando da Silva",
    "section": "Software",
    "text": "Software\n\n\n{meedr}\n\n\nAn R client for the Central Bank of Brazil macroeconomic expectations data API.\n\n\nCode Details \n\n\n\n\n{nucleos}\n\n\nAn R package to collect disaggregated inflation data and calculate inflation core measures for Brazil.\n\n\nCode Details"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Fernando da Silva",
    "section": "",
    "text": "You can view my resume (in English) below or download it through this link."
  },
  {
    "objectID": "cv.html#resume",
    "href": "cv.html#resume",
    "title": "Fernando da Silva",
    "section": "",
    "text": "You can view my resume (in English) below or download it through this link."
  },
  {
    "objectID": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html",
    "href": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html",
    "title": "5 armadilhas dos dados (macro)econômicos no Brasil",
    "section": "",
    "text": "Diariamente os economistas utilizam uma grande variedade de dados que são de difícil mensuração e que, portanto, são estimados/coletados por terceiros (IBGE, BCB, etc.). A falta de investigação aprofundada sobre como esses dados são produzidos, entendendo seus pontos fortes e suas limitações, pode nos levar a cair em algumas “armadilhas” peculiares.\nApesar de as fontes públicas de dados econômicos e financeiros do Brasil serem aderentes as “boas práticas” de dados do FMI - conforme o site dedicado ao assunto intitulado “Dissemination Standards Bulletin Board (DSBB)” -, o tema de qualidade de dados (macro)econômicos por essas bandas é sempre produtivo. Problemas de consistência, mudança de metodologia, disponibilidade e acesso a bancos de dados são corriqueiros no dia a dia de quem trabalha com esses dados, de modo que, mesmo que se queira fazer uma simples análise, você provavelmente precisará “matar um leão por dia”. Em um contexto mais amplo, frequentemente circulam notícias reportando algum tipo de desvario observado em dados públicos, desde na área da saúde até em dados de programas sociais.\nApesar dos problemas, dados são o sangue que corre na veia de quase todo macroeconomista - eles não sobrevivem sem! - sendo imprescindível conhecer suas nuances. Dessa forma, destacamos abaixo 5 casos das principais armadilhas e nuances dos dados (macro)econômicos brasileiros:"
  },
  {
    "objectID": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#dados-simplesmente-somem",
    "href": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#dados-simplesmente-somem",
    "title": "5 armadilhas dos dados (macro)econômicos no Brasil",
    "section": "1) Dados simplesmente somem",
    "text": "1) Dados simplesmente somem\nTalvez a “armadilha” mais gritante seja a situação inesperada de determinado dado, que você habitualmente utiliza, simplesmente… sumir. Nessas circunstâncias, o primeiro palpite razoável que pode surgir é que a pesquisa/variável/etc. pode ter sido descontinuada pela fonte primária. Mas, como é o caso de diversas variáveis, os dados são geralmente mantidos no banco de dados para acesso, mesmo que não haja ingestão de dados novos. Não foi o caso, por exemplo, do que aconteceu alguns meses atrás com as tabelas 6390 e 6392 da PNAD Contínua mensal, disponibilizada no SIDRA/IBGE, das quais as variáveis referentes a massa e rendimento real simplesmente sumiram. Apesar de esses dados já terem sido reestabelecidos, pelo menos até a data de hoje, fica a lição: pode ser útil você ter e manter o seu próprio banco de dados!"
  },
  {
    "objectID": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#dados-mudam-constantemente",
    "href": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#dados-mudam-constantemente",
    "title": "5 armadilhas dos dados (macro)econômicos no Brasil",
    "section": "2) Dados mudam constantemente",
    "text": "2) Dados mudam constantemente\nAquela frase que diz que “no Brasil até o passado é incerto” é tão verdadeira que até mesmo sua autoria é questionável - alguns atribuem a Pedro Malan, outros a Gustavo Loyola. E em se tratando de dados macroeconômicos, essa incerteza é até esperada, pois diversas estatísticas produzidas em um país - como as Contas Nacionais, por exemplo - são revisadas com frequência. Portanto, não se deve assumir que aqueles gráficos e tabelas bonitas vistos por aí continuarão com os mesmos valores históricos para sempre.\nUm caso recente dessa armadilha aconteceu com os dados de 2020 do saldo de empregos do CAGED (que já tem histórico de mudanças metodológicas), após uma revisão expressiva. Portanto, se você utiliza com frequência dados passíveis de revisão, o melhor remédio para evitar dor de cabeça é sempre atualizar a série total, não apenas as novas observações mais recentemente divulgadas."
  },
  {
    "objectID": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#dados-são-imprecisos",
    "href": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#dados-são-imprecisos",
    "title": "5 armadilhas dos dados (macro)econômicos no Brasil",
    "section": "3) Dados são imprecisos",
    "text": "3) Dados são imprecisos\nNão podemos também escapar de problemas de acurácia, erros de medida, de registro e de coleta dos dados que, apesar disso, estão diariamente na mídia. Na maioria dos casos, dados que são provenientes de pesquisas (surveys) estão mais propensos a apresentar estas armadilhas, mas não limitado a esse tipo de dado. Por exemplo, você sabia que em diversos meses os pesos dos subitens do IPCA não somam 100%, considerando 4 casas decimais? Ou que no Sistema de Expectativas (Focus) do Banco Central do Brasil estão registradas expectativas em certas datas para variáveis cujo valor real já havia sido divulgado? São casos, no mínimo, curiosos e que passam despercebidos.\nNo caso dos pesos do IPCA alguém pode argumentar um certo preciosismo ao considerar 4 casas decimais - de fato é - e outrem poderia ponderar que se o dado é divulgado com 4 casas decimais, espera-se que, pela metodologia, feche 100%. Já no caso das expectativas do Focus, preocupa o fato de que dados com tal “sujeira” guiem as decisões do COPOM, afinal o sistema não deveria aceitar ou registrar expectativas para variáveis cujo valor/horizonte de previsão já é sabido.\nSobre imprecisão e qualidade dos dados, aproveito a oportunidade para resgatar a ótima tirinha de Calvin e Haroldo sobre o assunto:"
  },
  {
    "objectID": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#metodologias-dos-dados-mudam",
    "href": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#metodologias-dos-dados-mudam",
    "title": "5 armadilhas dos dados (macro)econômicos no Brasil",
    "section": "4) Metodologias dos dados mudam",
    "text": "4) Metodologias dos dados mudam\nDe tempos em tempos as metodologias e definições de dados podem mudar, em alguns casos de maneira programática e em outros inesperadamente. Dependendo da alteração, como no caso recente e famoso do CAGED, pode-se inviabilizar a comparação dos dados pré e pós mudança metodológica. Isso torna obrigatória a leitura das notas de rodapé associadas a divulgação dos dados, além da página de histórico das mudanças da pesquisa na internet, pois tais mudanças e rupturas nas séries afetam a análise dos dados.\nAlém disso, vale enfatizar que também há problemas quando as metodologias não mudam quando deveriam mudar, ou seja, pesquisas que estão defasadas e precisam de atualização. Isso foi (tem sido) especialmente importante nos tempos recentes de pandemia e seus choques, onde, por exemplo, indicadores que mensuram a inflação no país utilizam estruturas de consumo das famílias de 2017-18, mas isso é outra discussão."
  },
  {
    "objectID": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#disponibilidade-de-dados-públicos-é-precária",
    "href": "blog/2021-11-27-armadilhas-dos-dados-macro-no-brasil/index.html#disponibilidade-de-dados-públicos-é-precária",
    "title": "5 armadilhas dos dados (macro)econômicos no Brasil",
    "section": "5) Disponibilidade de dados públicos é precária",
    "text": "5) Disponibilidade de dados públicos é precária\nA questão de infraestrutura para disponibilidade e acesso aos dados econômicos também merece atenção. Dados disponibilizados em formatos arcaicos - como planilhas de Excel com formatação pouco convidativa -, sites instáveis ou que ficam fora do ar, limitações de download/requisição e até mesmo a própria usabilidade dos sites e fontes públicas brasileiras são alguns dos problemas mais frequentes e que ninguém escapa. Apesar de avanços, nos dados macroeconômicos o âmbito fiscal parece ser o mais problemático. Por exemplo, há alguns meses a planilha de resultado primário do Tesouro Nacional ficou indisponível por cerca de 2 semanas.\nPor fim, enfatizo que instituições brasileiras como o IBGE cumprem um papel fundamental no país e, atualmente, são respeitadas nacional e internacionalmente pelo seu trabalho. Este texto não visa realizar críticas, mas apenas relata fatos do dia a dia de quem lida com dados (macro)econômicos, acendendo o alerta para os mais iniciantes. Comentários são bem-vindos!\n\nInformações da sessão\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 19045)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Portuguese_Brazil.utf8\n ctype    Portuguese_Brazil.utf8\n tz       America/Sao_Paulo\n date     2023-03-10\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.335 @ C:\\\\PROGRA~1\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.4.1   2022-09-23 [1] CRAN (R 4.2.1)\n digest        0.6.29  2021-12-01 [1] CRAN (R 4.2.1)\n evaluate      0.17    2022-10-07 [1] CRAN (R 4.2.1)\n fastmap       1.1.0   2021-01-25 [1] CRAN (R 4.2.1)\n glue          1.6.2   2022-02-24 [1] CRAN (R 4.2.1)\n htmltools     0.5.3   2022-07-18 [1] CRAN (R 4.2.1)\n htmlwidgets   1.5.4   2021-09-08 [1] CRAN (R 4.2.1)\n jsonlite      1.8.4   2022-12-06 [1] CRAN (R 4.2.2)\n knitr         1.40    2022-08-24 [1] CRAN (R 4.2.1)\n lifecycle     1.0.3   2022-10-07 [1] CRAN (R 4.2.1)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.2.1)\n rlang         1.0.6   2022-09-24 [1] CRAN (R 4.2.1)\n rmarkdown     2.17    2022-10-07 [1] CRAN (R 4.2.1)\n rstudioapi    0.14    2022-08-22 [1] CRAN (R 4.2.1)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n stringi       1.7.8   2022-07-11 [1] CRAN (R 4.2.1)\n stringr       1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n vctrs         0.5.1   2022-11-16 [1] CRAN (R 4.2.1)\n xfun          0.33    2022-09-12 [1] CRAN (R 4.2.1)\n yaml          2.3.5   2022-02-21 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/ferna/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nCompartilhar:"
  },
  {
    "objectID": "blog/2021-03-13-meedr-r-package/index.html",
    "href": "blog/2021-03-13-meedr-r-package/index.html",
    "title": "meedr: MacroEconomic Expectations Data in R",
    "section": "",
    "text": "Very happy to announce that {meedr}, my first package on R, is on its way to CRAN!\nNote: This package was definitively archived by CRAN on July 22, 2021 and is only available on GitHub. Despite this, maintenance and bug fixes will continue to be done.\nThe {meedr} package offers an R interface to the API and other advantages:"
  },
  {
    "objectID": "blog/2021-03-13-meedr-r-package/index.html#installation",
    "href": "blog/2021-03-13-meedr-r-package/index.html#installation",
    "title": "meedr: MacroEconomic Expectations Data in R",
    "section": "Installation",
    "text": "Installation\nYou can install the development version from GitHub with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"schoulten/meedr\")"
  },
  {
    "objectID": "blog/2021-03-13-meedr-r-package/index.html#features",
    "href": "blog/2021-03-13-meedr-r-package/index.html#features",
    "title": "meedr: MacroEconomic Expectations Data in R",
    "section": "Features",
    "text": "Features\n\nTo retrieve data from the API, there are several useful functions that connect to the endpoints:\n\nMonthly market expectations with get_monthly()\n\nQuarterly market expectations with get_quarterly()\n\nAnnual market expectations with get_annual()\n\nMarket expectations for inflation over the next 12 months with get_inflation_12m()\n\nMonthly market expectations for the Top 5 indicators with get_monthly_top5()\n\nAnnual market expectations for the Top 5 indicators with get_annual_top5()"
  },
  {
    "objectID": "blog/2021-03-13-meedr-r-package/index.html#example",
    "href": "blog/2021-03-13-meedr-r-package/index.html#example",
    "title": "meedr: MacroEconomic Expectations Data in R",
    "section": "Example",
    "text": "Example\nThese are some basic examples of using the package:\nget_monthly()\n\nCodelibrary(meedr)\n\n# Monthly market expectations for IPCA indicator\nmeedr::get_monthly(\n  indicator      = \"IPCA\",\n  first_date     = Sys.Date() - 30,\n  reference_date = format(Sys.Date(), \"%m/%Y\"),\n  be_quiet       = TRUE\n  )\n\n# A tibble: 32 × 10\n   indicator date       reference…¹  mean median    sd   min   max n_res…² basis\n   &lt;chr&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n 1 IPCA      2023-03-03 03/2023     0.719  0.72  0.135  0.4   1.01      57     1\n 2 IPCA      2023-03-03 03/2023     0.715  0.7   0.197  0.2   1.41     146     0\n 3 IPCA      2023-03-02 03/2023     0.692  0.69  0.158  0.38  1.02      53     1\n 4 IPCA      2023-03-02 03/2023     0.710  0.665 0.209  0.2   1.41     146     0\n 5 IPCA      2023-03-01 03/2023     0.686  0.66  0.167  0.38  1.02      51     1\n 6 IPCA      2023-03-01 03/2023     0.707  0.657 0.213  0.2   1.41     144     0\n 7 IPCA      2023-02-28 03/2023     0.709  0.65  0.213  0.38  1.41      56     1\n 8 IPCA      2023-02-28 03/2023     0.704  0.65  0.220  0.2   1.41     142     0\n 9 IPCA      2023-02-27 03/2023     0.725  0.69  0.217  0.2   1.41     107     1\n10 IPCA      2023-02-27 03/2023     0.703  0.65  0.219  0.2   1.41     142     0\n# … with 22 more rows, and abbreviated variable names ¹​reference_date,\n#   ²​n_respondents\n\n\nget_quarterly()\n\nCode# Quarterly market expectations for GDP indicator\nmeedr::get_quarterly(\n  indicator      = \"PIB Total\",\n  first_date     = \"2021-01-01\",\n  reference_date = paste0(\n    lubridate::quarter(Sys.Date()), \"/\", \n    lubridate::year(Sys.Date())\n    ),\n  be_quiet       = TRUE\n  )\n\n# A tibble: 884 × 10\n   indicator date       reference…¹  mean median    sd   min   max n_res…² basis\n   &lt;chr&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n 1 PIB Total 2023-03-03 1/2023       1.72   1.64 1.03   -0.4  4.69      30     1\n 2 PIB Total 2023-03-03 1/2023       1.76   1.69 0.785  -0.4  4.69      84     0\n 3 PIB Total 2023-03-02 1/2023       1.82   1.86 1.11   -0.4  4.69      27     1\n 4 PIB Total 2023-03-02 1/2023       1.73   1.64 0.800  -0.4  4.69      84     0\n 5 PIB Total 2023-03-01 1/2023       1.76   1.86 0.994  -0.4  3.8       25     1\n 6 PIB Total 2023-03-01 1/2023       1.71   1.6  0.769  -0.4  3.8       85     0\n 7 PIB Total 2023-02-28 1/2023       1.67   1.7  0.911  -0.4  3.8       37     1\n 8 PIB Total 2023-02-28 1/2023       1.71   1.6  0.769  -0.4  3.8       85     0\n 9 PIB Total 2023-02-27 1/2023       1.72   1.68 0.834  -0.4  3.8       65     1\n10 PIB Total 2023-02-27 1/2023       1.71   1.6  0.769  -0.4  3.8       85     0\n# … with 874 more rows, and abbreviated variable names ¹​reference_date,\n#   ²​n_respondents\n\n\nget_annual()\n\nCode# Annual market expectations for SELIC and exchange rate (BRL) indicator\nmeedr::get_annual(\n  indicator      = c(\"Selic\", \"Câmbio\"),\n  reference_date = format(Sys.Date(), \"%Y\"),\n  be_quiet       = TRUE\n  )\n\n# A tibble: 1,970 × 11\n   indicator detail date       referenc…¹  mean median    sd   min   max n_res…²\n   &lt;chr&gt;     &lt;lgl&gt;  &lt;date&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 Selic     NA     2023-03-03 2023       12.9   12.8  0.739 10.8   13.8     136\n 2 Selic     NA     2023-03-03 2023       12.9   12.8  0.710 11     13.8      44\n 3 Câmbio    NA     2023-03-03 2023        5.23   5.25 0.166  4.7    5.8     115\n 4 Câmbio    NA     2023-03-03 2023        5.20   5.2  0.171  4.8    5.6      38\n 5 Selic     NA     2023-03-02 2023       12.9   12.8  0.743 10.8   13.8     136\n 6 Selic     NA     2023-03-02 2023       12.9   12.8  0.668 11.2   13.8      45\n 7 Câmbio    NA     2023-03-02 2023        5.24   5.25 0.168  4.7    5.8     115\n 8 Câmbio    NA     2023-03-02 2023        5.24   5.26 0.170  4.85   5.6      40\n 9 Selic     NA     2023-03-01 2023       12.9   12.8  0.747 10.8   13.8     134\n10 Selic     NA     2023-03-01 2023       12.8   12.8  0.738 11     13.8      47\n# … with 1,960 more rows, 1 more variable: basis &lt;int&gt;, and abbreviated\n#   variable names ¹​reference_date, ²​n_respondents\n\n\nget_inflation_12m()\n\nCode# Inflation over the next 12 months\n# First, and a suggestion, run this for using parallel computing:\nfuture::plan(future::multisession, workers = floor(future::availableCores()/2))\nmeedr::get_inflation_12m(\n  indicator   = c(\n    \"IGP-DI\", \"IGP-M\", \"INPC\", \"IPA-DI\", \"IPA-M\", \"IPCA\", \"IPCA-15\", \"IPC-Fipe\"\n    ),\n  smoothed    = \"yes\",\n  be_quiet    = FALSE, # display messages\n  do_parallel = TRUE # turn on parallel computing\n  )\n\n\nRunning parallel with 2 cores (4 available)\n\nFetching [IGP-DI, IGP-M, INPC, IPA-DI, IPA-M, IPCA, IPCA-15, IPC-Fipe] data from BCB-Olinda... \n\n\n\nFound 1985 observations!\n\n\n# A tibble: 1,985 × 10\n   indicator date       smoothed  mean median    sd   min   max n_respon…¹ basis\n   &lt;chr&gt;     &lt;date&gt;     &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n 1 IGP-M     2023-03-03 yes       4.71   4.79 0.937  2.59  7.33         59     0\n 2 IGP-M     2023-03-03 yes       4.85   4.84 1.13   2.59  7.33         18     1\n 3 IPCA      2023-03-03 yes       5.56   5.60 0.452  3.80  6.62        117     0\n 4 IPCA      2023-03-03 yes       5.56   5.64 0.512  3.94  6.62         42     1\n 5 IGP-M     2023-03-02 yes       4.74   4.79 0.963  2.58  8.28         61     0\n 6 IGP-M     2023-03-02 yes       4.74   4.61 1.28   2.58  8.28         15     1\n 7 IPCA      2023-03-02 yes       5.56   5.58 0.452  3.81  6.61        116     0\n 8 IPCA      2023-03-02 yes       5.53   5.44 0.497  3.95  6.61         33     1\n 9 IGP-M     2023-03-01 yes       4.76   4.81 0.934  2.94  8.27         60     0\n10 IGP-M     2023-03-01 yes       4.92   4.85 1.23   3.35  8.27         13     1\n# … with 1,975 more rows, and abbreviated variable name ¹​n_respondents\n\n\nget_monthly_top5()\n\nCode# Monthly market expectations for IGP-M indicator (Top 5 Focus)\nmeedr::get_monthly_top5(\n  indicator  = \"IGP-M\",\n  first_date = NULL, # get all data to current date\n  calc_type  = \"long\",\n  be_quiet   = TRUE\n  )\n\n# A tibble: 77,024 × 9\n   indicator date       reference_date calc_type  mean median     sd   min   max\n   &lt;chr&gt;     &lt;date&gt;     &lt;chr&gt;          &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 IGP-M     2022-02-18 02/2022        L         1.70    1.8  0.306   1.1   1.95\n 2 IGP-M     2022-02-18 03/2022        L         0.798   0.75 0.133   0.64  1   \n 3 IGP-M     2022-02-18 04/2022        L         0.592   0.45 0.244   0.35  1   \n 4 IGP-M     2022-02-18 05/2022        L         0.448   0.33 0.271   0.2   0.9 \n 5 IGP-M     2022-02-18 06/2022        L         0.574   0.5  0.133   0.41  0.76\n 6 IGP-M     2022-02-18 07/2022        L         0.46    0.43 0.0953  0.35  0.6 \n 7 IGP-M     2022-02-18 08/2022        L         0.476   0.5  0.0931  0.36  0.62\n 8 IGP-M     2022-02-18 09/2022        L         0.536   0.5  0.104   0.4   0.7 \n 9 IGP-M     2022-02-18 10/2022        L         0.534   0.5  0.065   0.45  0.62\n10 IGP-M     2022-02-18 11/2022        L         0.574   0.6  0.114   0.44  0.76\n# … with 77,014 more rows\n\n\nget_annual_top5()\n\nCode# Annual market expectations for SELIC indicator (Top 5 Focus)\nmeedr::get_annual_top5(\n  indicator   = \"Selic\",\n  be_quiet    = TRUE,\n  use_memoise = FALSE # disable caching system\n  )\n\n# A tibble: 6,134 × 9\n   indicator date       reference_date calc_type  mean median    sd   min   max\n   &lt;chr&gt;     &lt;date&gt;     &lt;chr&gt;          &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Selic     2023-03-03 2023           S         12.8   12.8  0.857 10.8   13.8\n 2 Selic     2023-03-03 2024           S         10.2   10    1.10   8.25  13.8\n 3 Selic     2023-03-03 2025           S          8.81   9    0.968  6     11  \n 4 Selic     2023-03-03 2026           S          8.60   8.5  1.08   5     11  \n 5 Selic     2023-03-03 2027           S          8.54   8.5  1.15   5     11  \n 6 Selic     2023-03-03 2023           L         12.6   12.5  0.663 11.8   13.8\n 7 Selic     2023-03-03 2024           L          9.9   10    0.860  8.5   11  \n 8 Selic     2023-03-03 2025           L          9.55   9.5  0.678  8.5   10.5\n 9 Selic     2023-03-03 2026           L          9.4    9.5  0.8    8.5   10.5\n10 Selic     2023-03-03 2027           L          9.62   9.75 0.740  8.5   10.5\n# … with 6,124 more rows"
  },
  {
    "objectID": "blog/2021-03-13-meedr-r-package/index.html#data-visualization",
    "href": "blog/2021-03-13-meedr-r-package/index.html#data-visualization",
    "title": "meedr: MacroEconomic Expectations Data in R",
    "section": "Data visualization",
    "text": "Data visualization\nNow we will create a cool chart about inflation expectations in Brazil. First, we will import the data from the Central Bank API using {meedr}:\n\nCode# Get market expectations for inflation over the next 12 months\ninflation &lt;- meedr::get_inflation_12m(\n  indicator   = \"IPCA\",\n  first_date  = Sys.Date() - months(5 * 12),\n  smoothed    = \"yes\"\n  )\n\n\nNext, we use ggplot2 to generate a customized line chart. We plot the median of expectations and one standard deviation to observe some data distribution.\n\nCode# Plot\ninflation |&gt; \n  dplyr::filter(basis == 0) |&gt; \n  ggplot2::ggplot() +\n  ggplot2::aes(x = date) +\n  ggplot2::geom_ribbon(\n    mapping = ggplot2::aes(ymin = median - sd, ymax = median + sd),\n    alpha   = 0.2, \n    fill    = \"#282f6b\"\n    ) +\n  ggplot2::geom_line(\n    mapping = ggplot2::aes(y = median - sd), \n    size    = 0.5, \n    color   = \"#282f6b\"\n      ) +\n  ggplot2::geom_line(\n    mapping = ggplot2::aes(y = median + sd), \n    size    = 0.5, \n    color   = \"#282f6b\"\n      ) +\n  ggplot2::geom_line(\n    mapping = ggplot2::aes(y = median, colour = \"IPCA\"),\n    size    = 1, \n    color   = \"#b22200\"\n    ) +\n  ggplot2::scale_x_date(date_breaks = \"9 months\", date_labels = \"%m/%Y\") +\n  ggplot2::labs(\n    title    = \"Brazil: Market expectations for inflation over the next 12 months\",\n    subtitle = \"Smoothed median and standard deviation, IPCA\",\n    x        = NULL,\n    y        = \"%\",\n    caption  = \"**Data**: BCB | **Chart**: Fernando da Silva\"\n    ) +\n  ggplot2::theme_light(base_size = 16) +\n  ggplot2::theme(\n    plot.title   = ggplot2::element_text(face = \"bold\"),\n    plot.caption = ggtext::element_textbox_simple(\n      margin = ggplot2::margin(10, 0, 0, 0)\n      ),\n    plot.title.position   = \"plot\",\n    plot.caption.position = \"plot\",\n    axis.text             = ggplot2::element_text(face = \"bold\"),\n    axis.title            = ggplot2::element_text(face = \"bold\"),\n    legend.text           = ggplot2::element_text(face = \"bold\")\n    )\n\n\n\n\nAnd that’s it!\nThe process of developing a package is a lot of learning and enrichment. Soon I intend to increase the package with new utilities. In the meantime, feel free to use and test the package, I will be happy to receive any feedback!"
  },
  {
    "objectID": "blog/2021-03-13-meedr-r-package/index.html#github-repo-and-documentation",
    "href": "blog/2021-03-13-meedr-r-package/index.html#github-repo-and-documentation",
    "title": "meedr: MacroEconomic Expectations Data in R",
    "section": "GitHub repo and documentation",
    "text": "GitHub repo and documentation\nCheck the source code and other information in the package repository on GitHub.\nCheck the package documentation on this page.\n\nInformações da sessão\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 19045)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Portuguese_Brazil.utf8\n ctype    Portuguese_Brazil.utf8\n tz       America/Sao_Paulo\n date     2023-03-10\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.335 @ C:\\\\PROGRA~1\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.1)\n cachem        1.0.6      2021-08-19 [1] CRAN (R 4.2.1)\n cli           3.4.1      2022-09-23 [1] CRAN (R 4.2.1)\n codetools     0.2-18     2020-11-04 [2] CRAN (R 4.2.1)\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.1)\n curl          4.3.3      2022-10-06 [1] CRAN (R 4.2.1)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.1)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.1)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.1)\n evaluate      0.17       2022-10-07 [1] CRAN (R 4.2.1)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.1)\n farver        2.1.1      2022-07-06 [1] CRAN (R 4.2.1)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.1)\n furrr         0.3.1      2022-08-15 [1] CRAN (R 4.2.1)\n future        1.28.0     2022-09-02 [1] CRAN (R 4.2.1)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.1)\n ggplot2       3.3.6      2022-05-03 [1] CRAN (R 4.2.1)\n ggtext        0.1.2      2022-09-16 [1] CRAN (R 4.2.1)\n globals       0.16.1     2022-08-28 [1] CRAN (R 4.2.1)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.1)\n gridtext      0.1.4.9000 2022-06-07 [1] Github (wilkelab/gridtext@6192174)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.1)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.1)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.1)\n httr          1.4.5      2023-02-24 [1] CRAN (R 4.2.2)\n jsonlite      1.8.4      2022-12-06 [1] CRAN (R 4.2.2)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.1)\n labeling      0.4.2      2020-10-20 [1] CRAN (R 4.2.0)\n lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.1)\n listenv       0.8.0      2019-12-05 [1] CRAN (R 4.2.1)\n lubridate     1.9.2      2023-02-10 [1] CRAN (R 4.2.2)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.1)\n markdown      1.1        2019-08-07 [1] CRAN (R 4.2.1)\n meedr       * 0.0.3      2022-08-12 [1] Github (schoulten/meedr@66f13cd)\n memoise       2.0.1      2021-11-26 [1] CRAN (R 4.2.1)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.1)\n parallelly    1.32.1     2022-07-21 [1] CRAN (R 4.2.1)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.1)\n purrr         0.3.5      2022-10-06 [1] CRAN (R 4.2.1)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.1)\n Rcpp          1.0.9      2022-07-08 [1] CRAN (R 4.2.1)\n rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.1)\n rmarkdown     2.17       2022-10-07 [1] CRAN (R 4.2.1)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.1)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.1)\n stringr       1.5.0      2022-12-02 [1] CRAN (R 4.2.2)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.1)\n tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.1)\n timechange    0.2.0      2023-01-11 [1] CRAN (R 4.2.2)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.1)\n vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.1)\n withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.1)\n xfun          0.33       2022-09-12 [1] CRAN (R 4.2.1)\n xml2          1.3.3      2021-11-30 [1] CRAN (R 4.2.1)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/ferna/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nCompartilhar:"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Fernando da Silva",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n11 min\n\n\n\nTime Series\n\n\nCointegration\n\n\nR\n\n\nPortuguês\n\n\n\nUma analogia sobre cointegração de Engle-Granger e uma aplicação em R\n\n\n\nFernando da Silva\n\n\nApr 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6 min\n\n\n\nMacroeconomics\n\n\nData\n\n\nPortuguês\n\n\n\nAs nuances que só descobrimos sujando as mãos nos dados brutos\n\n\n\nFernando da Silva\n\n\nNov 27, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14 min\n\n\n\nMacroeconomics\n\n\nR\n\n\nEconomic Cycle\n\n\nPortuguês\n\n\n\nUma visão geral sobre ciclos econômicos, o algoritmo e uma aplicação em R\n\n\n\nFernando da Silva\n\n\nJul 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6 min\n\n\n\nR\n\n\nMacroeconomics\n\n\nData\n\n\nAPI\n\n\nEnglish\n\n\n\nQuick and easy access to market expectations data of the Focus report from Central Bank of Brazil\n\n\n\nFernando da Silva\n\n\nMar 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8 min\n\n\n\nMacroeconomics\n\n\nMonetary Policy\n\n\nR\n\n\nPortuguês\n\n\n\nO porquê e o como de analisar o preço do dinheiro ao longo do tempo, com uma aplicação em R\n\n\n\nFernando da Silva\n\n\nFeb 24, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html#blog",
    "href": "blog.html#blog",
    "title": "Fernando da Silva",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n11 min\n\n\n\nTime Series\n\n\nCointegration\n\n\nR\n\n\nPortuguês\n\n\n\nUma analogia sobre cointegração de Engle-Granger e uma aplicação em R\n\n\n\nFernando da Silva\n\n\nApr 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6 min\n\n\n\nMacroeconomics\n\n\nData\n\n\nPortuguês\n\n\n\nAs nuances que só descobrimos sujando as mãos nos dados brutos\n\n\n\nFernando da Silva\n\n\nNov 27, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14 min\n\n\n\nMacroeconomics\n\n\nR\n\n\nEconomic Cycle\n\n\nPortuguês\n\n\n\nUma visão geral sobre ciclos econômicos, o algoritmo e uma aplicação em R\n\n\n\nFernando da Silva\n\n\nJul 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6 min\n\n\n\nR\n\n\nMacroeconomics\n\n\nData\n\n\nAPI\n\n\nEnglish\n\n\n\nQuick and easy access to market expectations data of the Focus report from Central Bank of Brazil\n\n\n\nFernando da Silva\n\n\nMar 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8 min\n\n\n\nMacroeconomics\n\n\nMonetary Policy\n\n\nR\n\n\nPortuguês\n\n\n\nO porquê e o como de analisar o preço do dinheiro ao longo do tempo, com uma aplicação em R\n\n\n\nFernando da Silva\n\n\nFeb 24, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2021-02-24-calculo-do-juro-real/index.html",
    "href": "blog/2021-02-24-calculo-do-juro-real/index.html",
    "title": "Cálculo da taxa de juros real: ex post e ex ante",
    "section": "",
    "text": "O dinheiro existe há bastante tempo e, geralmente, pagamos para poder usar o dinheiro e/ou poupança de outra pessoa (afinal, não existe almoço grátis). O preço dessa troca, entre o credor e o devedor, é o que usualmente se chama de juros. Também é comum que essa taxa, chamada de juros nominal, seja positiva e definida como um referencial pelo Banco Central de cada país, constituindo um dos principais instrumentos de controle da inflação.\nSabendo que a taxa de juros nominal é um preço, logo, há motivos para deflacioná-lo por um índice de correção de preços como o IPCA, por exemplo, de forma semelhante ao que fazemos quando é necessário “corrigir” o valor de um imóvel que irá à venda. O resultado dessa operação é o que é chamado de taxa de juros real, ou seja, a taxa nominal deflacionada pela taxa de inflação.\nTambém é com a taxa de juros real, em conjunto com uma outra taxa — a taxa neutra, que é uma taxa de juros teórica, consistente com a estabilidade da inflação ao longo do tempo —, que é possível analisar a condução da política monetária de uma economia. A política monetária é dita “contracionista” quando a taxa de juros real está acima da taxa de juros neutra, ou seja, a autoridade monetária está com a taxa de juros em território que desincentiva a tomada de crédito, os investimentos e o consumo de maneira geral. Do contrário, a política monetária é dita “expansionista”."
  },
  {
    "objectID": "blog/2021-02-24-calculo-do-juro-real/index.html#conceitos-ex-post-e-ex-ante",
    "href": "blog/2021-02-24-calculo-do-juro-real/index.html#conceitos-ex-post-e-ex-ante",
    "title": "Cálculo da taxa de juros real: ex post e ex ante",
    "section": "Conceitos ex-post e ex-ante",
    "text": "Conceitos ex-post e ex-ante\nExistem basicamente duas perspectivas sobre a taxa de juros real: pelo conceito ex-post e pelo conceito ex-ante. No primeiro caso olhamos o comportamento dos juros no período passado, geralmente usando valores acumulados em 12 meses, o que nos permite verificar a tendência de juros real da economia; enquanto que no segundo caso é o oposto, estamos interessados em verificar o comportamento do juros real à frente, tomando como base expectativas de agentes de mercado, assim é possível identificar como é esperado o comportamento dos juros no futuro.\nDe forma mais visual, esses conceitos podem se traduzir em uma realidade da economia do país bastante impressionante se olharmos um período de tempo suficientemente grande, conforme a imagem abaixo:"
  },
  {
    "objectID": "blog/2021-02-24-calculo-do-juro-real/index.html#cálculo-do-juros-real",
    "href": "blog/2021-02-24-calculo-do-juro-real/index.html#cálculo-do-juros-real",
    "title": "Cálculo da taxa de juros real: ex post e ex ante",
    "section": "Cálculo do juros real",
    "text": "Cálculo do juros real\nPara chegar ao resultado que determina o juros real da economia usamos a equação de Fisher, através da fórmula bem simples a seguir:\n\\[r = \\left(\\frac{1+i}{1+\\pi}\\right)-1\\] Onde os termos significam:\n\\(r\\) = taxa de juros real\\(i\\) = taxa de juros nominal\\(\\pi\\) = taxa de inflação\nNote que se os dados estiverem expressos em percentual (% a.m., % a.a., etc.), você deve dividir o termo correspondente por 100 na fórmula acima."
  },
  {
    "objectID": "blog/2021-02-24-calculo-do-juro-real/index.html#juros-real-no-brasil",
    "href": "blog/2021-02-24-calculo-do-juro-real/index.html#juros-real-no-brasil",
    "title": "Cálculo da taxa de juros real: ex post e ex ante",
    "section": "Juros real no Brasil",
    "text": "Juros real no Brasil\nExplicados brevemente estes conceitos e dado uma prévia do resultado que queremos chegar, podemos partir para uma aplicação do cálculo das taxas para a economia brasileira.\nNo caso da taxa de juros real ex-ante, opto aqui por utilizar a taxa do Swap DI-Pré 360 dias e as expectativas de IPCA esperado também de 1 ano à frente, provenientes da B3 e do boletim Focus/BCB respectivamente. Há outras maneiras de obter essa taxa, para uma discussão sobre o assunto recomendo esse texto do Bráulio Borges e Gilberto Borça Jr. Já no caso da taxa de juros real ex-post usamos a taxa Selic acumulada no mês anualizada em base de 252 dias úteis e o IPCA acumulado em 12 meses, provenientes do BCB e do IBGE respectivamente.\nO que é necessário agora é obter esses dados e aplicar a equação de Fisher. A obtenção dos dados é bastante simples e rápida usando a linguagem R. Vamos usar as API’s de três fontes públicas de dados (IPEADATA, BCB e IBGE).\nPacotes\nPrimeiro carregamos os pacotes de R necessários (instale com install.packages() caso você não tenha algum instalado).\n\nCode# Carregar pacotes\nlibrary(rbcb)\nlibrary(ipeadatar)\nlibrary(sidrar)\nlibrary()\nlibrary()\n\n\nColeta de dados\nEm seguida utilizamos os parâmetros de cada API para obter os dados das fontes indicadas.\n\nCode# Expectativas IPCA em 12 meses\ndados_focus_12m &lt;- rbcb::get_market_expectations(\n  type = \"inflation-12-months\", \n  indic = \"IPCA\",\n  start_date = \"1999-01-01\"\n  )\n\n# Swaps DI pré 360\ndados_ipea &lt;- ipeadatar::ipeadata(\"BMF12_SWAPDI36012\")\n\n# SELIC acumulada no mês anualizada base 252\ndados_selic &lt;- rbcb::get_series(code = c(\"selic\" = 4189))\n\n# IPCA acumulado em 12 meses\ndados_ipca &lt;- sidrar::get_sidra(api = \"/t/1737/n1/all/v/2265/p/all/d/v2265%202\")\n\n\nTratamento de dados\nOs dados coletados precisam de alguns tratamentos para ficarem no formato desejado, o que envolve cruzar as tabelas, calcular médias, filtrar observações, etc.\n\nCode# Swaps DI pré 360\nswaps &lt;- dplyr::select(dados_ipea, \"data\" = \"date\", \"swaps\" = \"value\")\n\n# Expectativa média do IPCA em 12 meses\nfocus_12m &lt;- dados_focus_12m |&gt;\n  dplyr::filter(baseCalculo == 0 & Suavizada == \"S\") |&gt;\n  dplyr::group_by(data = lubridate::floor_date(Data, unit = \"month\")) |&gt;\n  dplyr::summarise(ipca_exp = mean(x = Mediana, na.rm = TRUE))\n\n# SELIC acumulada no mês anualizada base 252\nselic &lt;- dplyr::rename(dados_selic, \"data\" = \"date\")\n\n# IPCA acumulado em 12 meses\nipca &lt;- dados_ipca |&gt; \n  dplyr::mutate(\n    data     = lubridate::ym(`Mês (Código)`),\n    ipca_obs = Valor,\n    .keep    = \"none\"\n    ) |&gt; \n  dplyr::as_tibble()\n\n# Cruzar tabelas\ntabelas &lt;- purrr::reduce(\n  .x = list(swaps, focus_12m, selic, ipca),\n  .f = dplyr::full_join,\n  by = \"data\"\n  ) |&gt; \n  dplyr::arrange(data) |&gt; \n  dplyr::filter(data &gt;= lubridate::ymd(\"2001-12-01\"))\n\n# Exibe dados\ntail(tabelas)\n\n# A tibble: 6 × 5\n  data       swaps ipca_exp selic ipca_obs\n  &lt;date&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 2022-10-01  13.2     5.17  13.6     6.47\n2 2022-11-01  13.9     5.19  13.6     5.9 \n3 2022-12-01  13.8     5.26  13.6     5.79\n4 2023-01-01  13.5     5.41  13.6     5.77\n5 2023-02-01  13.4     5.66  13.6     5.6 \n6 2023-03-01  NA       5.59  13.6    NA   \n\n\nCalcular o juros real\nCom os dados em mãos, podemos finalmente aplicar a equação de Fisher. O resultado final será uma tabela com uma coluna com o período da observação, uma com o valor da taxa de juros real pelo conceito ex ante e outra pelo conceito ex-post.\n\nCode# Função útil para computar o cálculo\nfisher &lt;- function(juros, inflacao) {\n  r = ((1 + juros) / (1 + inflacao)) - 1\n  return(r)\n}\n\n# Cálculo da taxa de juros real\njuros_real &lt;- tabelas |&gt; \n  dplyr::mutate(\n    ex_ante = fisher(juros = swaps/100, inflacao = ipca_exp/100) * 100,\n    ex_post = fisher(juros = selic/100, inflacao = ipca_obs/100) * 100,\n    data    = data,\n    .keep   = \"none\"\n    )\n\n# Exibe dados\ntail(juros_real)\n\n# A tibble: 6 × 3\n  data       ex_ante ex_post\n  &lt;date&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 2022-10-01    7.60    6.74\n2 2022-11-01    8.26    7.32\n3 2022-12-01    8.15    7.43\n4 2023-01-01    7.70    7.45\n5 2023-02-01    7.34    7.62\n6 2023-03-01   NA      NA   \n\n\nExtra: visualização de dados\nPor fim vamos gerar um gráfico que mostra a evolução das duas séries. Eu gosto muito do pacote ggplot2, dá pra criar gráficos muito bonitos e com muita flexibilidade:\n\nCode# Gerar gráfico de linhas\njuros_real &lt;- juros_real |&gt;\n  tidyr::drop_na() |&gt; \n  tidyr::pivot_longer(cols = -\"data\", names_to = \"conceito\", values_to = \"juros\") |&gt; \n  dplyr::mutate(conceito = dplyr::if_else(conceito == \"ex_ante\", \"Ex ante\", \"Ex post\"))\n\nset.seed(1984)\nggplot2::ggplot(data = juros_real) +\n  ggplot2::aes(x = data, y = juros, color = conceito) +\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ggplot2::geom_line(size = 1) +\n  ggplot2::coord_cartesian(\n    clip = \"off\",\n    xlim = c(min(juros_real$data), max(juros_real$data) + months(12))\n    ) +\n  ggrepel::geom_label_repel(\n    data        = dplyr::filter(juros_real, data == max(data)),\n    mapping     = ggplot2::aes(\n      label = format(x = juros, big.mark = \".\", decimal.mark = \",\", digits = 2, nsmall = 2)\n      ),\n    show.legend    = FALSE,\n    nudge_x        = 70,\n    segment.colour = NA,\n    fontface       = \"bold\"\n    ) +\n  ggplot2::scale_color_manual(values = c(\"#282f6b\", \"#b22200\")) +\n  ggplot2::scale_x_date(breaks = \"3 years\", date_labels = \"%Y\") +\n  ggplot2::scale_y_continuous(labels = scales::label_percent(scale = 1, accuracy = 1)) +\n  ggplot2::labs(\n    title    = \"Brasil: taxa de juros real (% a.a.)\",\n    x        = NULL,\n    y        = NULL,\n    color    = NULL,\n    caption  = \"**Dados**: B3, BCB e IBGE | **Elaboração**: Fernando da Silva\"\n    ) +\n  ggplot2::theme_light(base_size = 16) +\n  ggplot2::theme(\n    plot.title      = ggplot2::element_text(face = \"bold\"),\n    plot.caption    = ggtext::element_textbox_simple(\n      margin = ggplot2::margin(10, 0, 0, 0)\n      ),\n    plot.title.position   = \"plot\",\n    plot.caption.position = \"plot\",\n    axis.text             = ggplot2::element_text(face = \"bold\"),\n    legend.text           = ggplot2::element_text(face = \"bold\"),\n    legend.position       = c(0.75, 0.9),\n    legend.key            = ggplot2::element_blank(),\n    legend.background     = ggplot2::element_blank(),\n    legend.direction      = \"horizontal\"\n    )\n\n\n\n\nVoilà! Eis o gráfico com os resultados do cálculo de juros real pelos conceitos ex-ante e ex-post. Espero que esse conteúdo tenha sido útil ou interessante para você. Até mais!\n\nInformações da sessão\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 19045)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Portuguese_Brazil.utf8\n ctype    Portuguese_Brazil.utf8\n tz       America/Sao_Paulo\n date     2023-03-10\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.335 @ C:\\\\PROGRA~1\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.1)\n cli           3.4.1      2022-09-23 [1] CRAN (R 4.2.1)\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.1)\n curl          4.3.3      2022-10-06 [1] CRAN (R 4.2.1)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.1)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.1)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.1)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.1)\n evaluate      0.17       2022-10-07 [1] CRAN (R 4.2.1)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.1)\n farver        2.1.1      2022-07-06 [1] CRAN (R 4.2.1)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.1)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.1)\n ggplot2       3.3.6      2022-05-03 [1] CRAN (R 4.2.1)\n ggrepel       0.9.1      2021-01-15 [1] CRAN (R 4.2.0)\n ggtext        0.1.2      2022-09-16 [1] CRAN (R 4.2.1)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.1)\n gridtext      0.1.4.9000 2022-06-07 [1] Github (wilkelab/gridtext@6192174)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.1)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.1)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.1)\n httr          1.4.5      2023-02-24 [1] CRAN (R 4.2.2)\n insight       0.19.0     2023-01-30 [1] CRAN (R 4.2.2)\n ipeadatar   * 0.1.6      2022-10-11 [1] Github (gomesleduardo/ipeadatar@9754e14)\n jsonlite      1.8.4      2022-12-06 [1] CRAN (R 4.2.2)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.1)\n labeling      0.4.2      2020-10-20 [1] CRAN (R 4.2.0)\n lattice       0.20-45    2021-09-22 [2] CRAN (R 4.2.1)\n lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.1)\n lubridate     1.9.2      2023-02-10 [1] CRAN (R 4.2.2)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.1)\n markdown      1.1        2019-08-07 [1] CRAN (R 4.2.1)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.1)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.1)\n purrr         0.3.5      2022-10-06 [1] CRAN (R 4.2.1)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.1)\n rbcb        * 0.1.10     2022-03-30 [1] CRAN (R 4.2.1)\n Rcpp          1.0.9      2022-07-08 [1] CRAN (R 4.2.1)\n rjson         0.2.21     2022-01-09 [1] CRAN (R 4.2.0)\n rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.1)\n rmarkdown     2.17       2022-10-07 [1] CRAN (R 4.2.1)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.1)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n sidrar      * 0.2.9      2022-07-12 [1] CRAN (R 4.2.0)\n sjlabelled    1.2.0      2022-04-10 [1] CRAN (R 4.2.1)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.1)\n stringr       1.5.0      2022-12-02 [1] CRAN (R 4.2.2)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.1)\n tidyr         1.2.1      2022-09-08 [1] CRAN (R 4.2.1)\n tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.1)\n timechange    0.2.0      2023-01-11 [1] CRAN (R 4.2.2)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.1)\n vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.1)\n withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.1)\n xfun          0.33       2022-09-12 [1] CRAN (R 4.2.1)\n xml2          1.3.3      2021-11-30 [1] CRAN (R 4.2.1)\n xts           0.13.0     2023-02-20 [1] CRAN (R 4.2.2)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.1)\n zoo           1.8-11     2022-09-17 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/ferna/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nCompartilhar:"
  },
  {
    "objectID": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html",
    "href": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html",
    "title": "Datação de ciclos econômicos e o algoritmo de Harding-Pagan",
    "section": "",
    "text": "Ao longo do tempo a economia apresenta o que se chama de ciclos econômicos, ou seja, períodos de expansão e recessão. Mas de que forma podemos saber em qual ponto do ciclo econômico a economia se encontra? Como sabemos se a economia está em recessão? Estas são perguntas de grande interesse para acadêmicos e profissionais da área, e neste breve exercício demonstramos como replicar a datação de ciclos econômicos que instituições como NBER (EUA) e CODACE (Brasil) tradicionalmente publicam."
  },
  {
    "objectID": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#a-importância-de-datar-o-ciclo-econômico",
    "href": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#a-importância-de-datar-o-ciclo-econômico",
    "title": "Datação de ciclos econômicos e o algoritmo de Harding-Pagan",
    "section": "A importância de datar o ciclo econômico",
    "text": "A importância de datar o ciclo econômico\nO ciclo econômico desempenha um papel importante para as decisões de política econômica e de empresas. Por exemplo, quando a economia está com hiato negativo, as empresas tendem a agir de forma mais conservadora. Em contrapartida, quando a economia está com hiato positivo, as empresas tendem a agir de forma mais agressiva com o objetivo de aumentar sua participação de mercado.\nA teoria do ciclos econômicos sugere que o ciclo econômico é um importante indicador para a política monetária, possibilitando a atuação do Banco Central para estabilizar as flutuações da economia. Portanto, a datação precisa do ciclo econômico pode ser fundamental para decisões políticas eficientes e práticas.\nNo Brasil o responsável pela datação do ciclo econômico é o Comitê de Datação de Ciclos Econômicos (CODACE), que se reúne periódicamente e publica um informativo contendo as datas dos períodos de expansão e recessão."
  },
  {
    "objectID": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#características-do-ciclo-econômico",
    "href": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#características-do-ciclo-econômico",
    "title": "Datação de ciclos econômicos e o algoritmo de Harding-Pagan",
    "section": "Características do ciclo econômico",
    "text": "Características do ciclo econômico\nHá diveros trabalhos que investigam a questão da datação de ciclos econômicos, aqui exploraremos apenas uma das abordagens. O procedimento completo é descrito em Harding e Pagan (2002) e é largamente utilizado em diversos países. Em resumo, os autores seguem a definição de Burns e Mitchell (1946) sobre ciclo econômico e propõem um método que entrega uma visualização gráfica do ciclo.\nExistem algumas características interessantes sobre as fases do ciclo econômico (fatos estilizados):\n\n\nPico (A): é o ponto de virada quando a expansão transita para a fase de recessão;\n\nVale (C): é o ponto de virada quando a recessão transita para a fase de expansão/recuperação;\n\nDuração (AB): é o número de trimestres entre o pico e o vale;\n\nAmplitude (BC): é a distância entre o pico e o vale ou altura do triângulo.\n\n\n\n\n\n\nA imagem acima ilustra didaticamente estas características."
  },
  {
    "objectID": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#o-algoritmo-de-harding-e-pagan-2002",
    "href": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#o-algoritmo-de-harding-e-pagan-2002",
    "title": "Datação de ciclos econômicos e o algoritmo de Harding-Pagan",
    "section": "O algoritmo de Harding e Pagan (2002)",
    "text": "O algoritmo de Harding e Pagan (2002)\nPartindo de uma série \\(Y_t\\) em frequência trimestral, representativa da atividade econômica (PIB) e usualmente transformada como \\(y_t = ln(Y_t)\\), a datação do ciclo econômico deve compreender as seguintes etapas:\n\nDeterminação de um conjunto potencial de pontos de virada, ou seja, os picos e vales em uma série \\(y_t\\);\nUm procedimento para garantir que os picos e os vales se alternem;\nUm conjunto de regras que recombinam os pontos de virada estabelecidos após os passos 1) e 2) para satisfazer critérios pré-determinados relativos à duração e amplitude das fases e ciclos completos (isso é chamado de “regras de censura”).\n\nConforme Harding e Pagan (2002), os pontos de virada da série acontecem quando:\n\\[\\begin{align*}\n  \\text{Pico na observação } t \\text{, se: } & \\left[(y_{t-k}, y_{t-1}) &lt; y_t &gt; (y_{t+1}, y_{t+k}) \\right] \\\\\n  \\text{Vale na observação } t \\text{, se: } & \\left[(y_{t-k}, y_{t-1}) &gt; y_t &lt; (y_{t+1}, y_{t+k}) \\right]\n\\end{align*}\\]\nO usual e recomendado pelos autores, para séries trimestrais, é definir \\(k = 2\\) para encontrar esses pontos máximos e mínimos locais.\nEm seguida, define-se as fases de expansão, recessão e o ciclo completo:\n\n\nRecessão: o período compreendido entre um pico e um vale;\n\nExpansão: o período compreendido entre um vale e um pico;\n\nCiclo completo: pode ser mensurado como a duração das fases de recessão e expansão somadas.\n\nPara tal, é necessário impor algumas “regras de censura”, que são restrições adicionais para eliminar/manter os pontos de virada identificados. Isso passa por definir uma duração mínima das fases de recessão/expansão entre picos/vales, geralmente utilizando-se 2 trimestres (inspirado no NBER). Além disso, restringe-se também a duração mínima do ciclo completo como 5 trimestres.\nEm resumo:\n\n\nRecessão/Expansão: duram, no mínimo, 2 trimestres;\n\nCiclo completo: dura, no mínimo, 5 trimestres.\n\nO método é bastante simples e poderoso, conseguindo praticamente replicar a cronologia de recessões desenvolvidas pelas instituições mencionadas acima."
  },
  {
    "objectID": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#datação-do-ciclo-econômico-do-brasil",
    "href": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#datação-do-ciclo-econômico-do-brasil",
    "title": "Datação de ciclos econômicos e o algoritmo de Harding-Pagan",
    "section": "Datação do ciclo econômico do Brasil",
    "text": "Datação do ciclo econômico do Brasil\nAgora passemos a aplicação do procedimento de datação do ciclo econômico, conforme Harding e Pagan (2002), exemplificando para a série trimestral do PIB brasileiro (série encadeada, ajustada sazonalmente).\nPacotes\nPara aplicar o algoritmo utilizaremos o pacote {BCDating} na linguagem R, criado por Majid Einian (Central Bank of Islamic Republic of Iran) e Franck Arnaud (National Institute of Statistics and Economic Studies, France). Outros pacotes são utilizados para coleta, tratamento e visualização de dados:\n\nCode# Carregar pacotes\nlibrary(BCDating)\nlibrary(sidrar)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(ggtext)\nlibrary(tidyr)\nlibrary(reactable)\nlibrary(reactablefmtr)\n\n\nDados\nNeste exercício utilizaremos a série do PIB a preços de mercado (série encadeada do índice de volume trimestral com ajuste sazonal, média de 1995 = 100), disponível no SIDRA/IBGE. Para coletar os dados via API pode-se usar o pacote sidrar, especificando o código de coleta. Além disso realizamos a preparação dos dados para utilização posterior:\n\nCode# Coleta e tratamento de dados\npib &lt;- sidrar::get_sidra(api = \"/t/1621/n1/all/v/all/p/all/c11255/90707/d/v584%202\") |&gt; \n  dplyr::mutate(\n    date = lubridate::yq(`Trimestre (Código)`),\n    value = Valor, \n    .keep = \"none\"\n    ) |&gt; \n  dplyr::as_tibble()\n\n# Inspeção dos dados\ntail(pib)\n\n# A tibble: 6 × 2\n  date       value\n  &lt;date&gt;     &lt;dbl&gt;\n1 2021-07-01  173.\n2 2021-10-01  175.\n3 2022-01-01  177.\n4 2022-04-01  179.\n5 2022-07-01  179.\n6 2022-10-01  179.\n\n\nDatação\nPara aplicar o algoritmo e obter as datações de ciclo de negócios, primeiro transformamos o objeto pro formato de série temporal e, em seguida, utilizamos a função BBQ() do pacote {BCDating}. Optamos por deixar com os valores predefinidos os demais argumentos da função, que servem para definir os valores mínimos de duração do ciclo (pico ao pico ou vale ao vale) e da fase do ciclo (pico ao vale ou vale ao pico).\n\nCode# Obter datação de ciclo de negócios\nbc_dates &lt;- stats::ts(\n  data = pib$value, \n  start = c(lubridate::year(min(pib$date)), lubridate::quarter(min(pib$date))),\n  frequency = 4\n  ) |&gt; \n  BCDating::BBQ(name = \"Ciclo de Negócios do PIB do Brasil\")\n\n\n# Inspeção do objeto\nclass(bc_dates)\n\n[1] \"BCDating\"\nattr(,\"package\")\n[1] \"BCDating\"\n\n\nResultados\nComo pode ser visto abaixo, o objeto retornado traz como resultado as datas (trimestres) de picos e vales, assim como a duração do ciclo.\n\nCode# Exibir resultados\nshow(bc_dates)\n\n   Peaks Troughs Duration\n1 2001Q1  2001Q4        3\n2 2002Q4  2003Q2        2\n3 2008Q3  2009Q1        2\n4 2014Q1  2016Q4       11\n5 2019Q4  2020Q2        2\n\n\nOutras informações podem ser obtidas com a função summary():\n\nCode# Informações adicionais\nsummary(bc_dates)\n\n       Phase ]Start  ;End] Duration LevStart LevEnd Amplitude\n1  Expansion   &lt;NA&gt; 2001Q1       NA       NA    114        NA\n2  Recession 2001Q1 2001Q4        3      114    112       1.5\n3  Expansion 2001Q4 2002Q4        4      112    118       5.8\n4  Recession 2002Q4 2003Q2        2      118    116       1.5\n5  Expansion 2003Q2 2008Q3       21      116    152      35.1\n6  Recession 2008Q3 2009Q1        2      152    144       7.8\n7  Expansion 2009Q1 2014Q1       20      144    177      33.2\n8  Recession 2014Q1 2016Q4       11      177    163      14.4\n9  Expansion 2016Q4 2019Q4       12      163    172       9.2\n10 Recession 2019Q4 2020Q2        2      172    153      18.4\n11 Expansion 2020Q2   &lt;NA&gt;       NA      153     NA        NA\n\n          Amplitude Duration\nExp=]T;P]      20.8     14.2\nRec=]P;T]       8.7      4.0\n\n\nPorém, o mais interessante é avaliar o resultado visualmente através de um gráfico. Para tal, fazemos um tratamento dos dados retornados pela função BBQ() e utilizamos o ggplot2 para gerar o gráfico com as áreas sombreadas referente às datas de recessão que foram identificadas pelo algoritmo, acompanhadas do comportamento do PIB no período:\n\nCode# Transformar resultados em tibble\nbc_dates_tbl &lt;- purrr::quietly(show)(bc_dates)$result |&gt; \n  dplyr::as_tibble() |&gt; \n  dplyr::mutate(\n    `Peaks`   = lubridate::yq(`Peaks`), \n    `Troughs` = lubridate::yq(`Troughs`)\n    )\n\n# Gerar gráfico\ng1 &lt;- ggplot2::ggplot() +\n  ggplot2::geom_rect(\n    data = bc_dates_tbl, \n    mapping = ggplot2::aes(\n      xmin = `Peaks`, xmax = `Troughs`, ymin = -Inf, ymax = Inf, \n      fill = \"Recessão\"\n      ),\n    alpha = 0.3\n    ) +\n  ggplot2::geom_line(\n    data = pib, \n    mapping = ggplot2::aes(x = date, y = value, colour = \"PIB s. a. (1995 = 100)\"), \n    size = 1.5\n    ) +\n  ggplot2::scale_colour_manual(values = \"dodgerblue4\") +\n  ggplot2::scale_fill_manual(values = \"grey50\") +\n  ggplot2::scale_x_date(date_breaks = \"4 years\", date_labels = \"%Y\") +\n  ggplot2::labs(\n    title    = \"Brasil: datação de ciclos econômicos\",\n    subtitle = \"Recessão datada pelo algoritmo de Harding-Pagan (2002)\",\n    y        = \"Índice\",\n    x        = NULL,\n    color    = NULL,\n    fill     = NULL,\n    caption  = \"**Dados:** IBGE | **Elaboração:** Fernando da Silva\"\n    ) +\n  ggthemes::theme_calc(base_size = 16) +\n  ggplot2::theme(\n    plot.title            = ggplot2::element_text(face = \"bold\"),\n    plot.title.position   = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.background       = ggplot2::element_rect(colour = NA),\n    plot.caption          =  ggtext::element_textbox_simple(\n      margin = ggplot2::margin(10, 0, 0, 0)\n      ),\n    legend.position = \"top\",\n    )\ng1\n\n\n\n\nComparação com cronologia do CODACE/FGV\nPor fim, vamos comparar os resultados aqui encontrados com a Cronologia de Ciclos de Negócios Brasileiros elaborada pelo CODACE. A última reunião do comitê foi em 29 de junho de 2020, na qual reportou a seguinte situação do ciclo de negócios:\n\nPercebe-se que a série utilizada pelo comitê inicia-se em 1980, mas se analisarmos a partir de 1996 (período de início da série utilizada em nosso exercício), verificamos que 5 de 6 recessões datadas pelo CODACE são identificadas pelo algoritmo de Harding & Pagan (2002). Apenas a recessão do 1º trimestre de 1998 ao 1º trimestre de 1999 não foi detectada. Apesar disso, o resultado é empolgante!\nPor fim, vamos comparar os resultados de ambas as datações mais a fundo na tabela a seguir, na qual contabilizamos o período de recessão partindo do trimestre imediatamente posterior ao pico até o subsequente vale:\n\nCodebc_dates_tbl |&gt; \n  dplyr::mutate(\n    dplyr::across(\n      .cols = c(\"Peaks\", \"Troughs\"), .fns = ~.x + months(3) # pois data de início não é inclusa\n      ),\n    dplyr::across(\n      .cols = c(\"Peaks\", \"Troughs\"), \n      .fns = ~paste0(\"T\", lubridate::quarter(.x), \"/\", lubridate::year(.x))\n      )\n    ) |&gt; \n  tidyr::unite(col = \"Período\", c(\"Peaks\", \"Troughs\"), sep = \" - \") |&gt; \n  dplyr::rename(\"Duração\" = `Duration`) |&gt; \n  dplyr::mutate(\n    `Período ` = c(\n      \"T2/2001 - T4/2001\", \n      \"T1/2003 - T2/2003\", \n      \"T4/2008 - T1/2009\", \n      \"T2/2014 - T4/2016\", \n      \"T1/2020 - ?\"\n      ),\n    `Duração ` = c(3, 2, 2, 11, \"?\")\n    ) |&gt; \n  reactable::reactable(\n    theme = reactablefmtr::flatly(),\n    columnGroups = list(\n      reactable::colGroup(name = \"Algoritmo H. & P.\", columns = c(\"Período\", \"Duração\")),\n      reactable::colGroup(name = \"Cronologia CODACE\", columns = c(\"Período \", \"Duração \"))\n      )\n    ) |&gt; \n  reactablefmtr::add_title(\n    title = \"Datação de recessões - Ciclo de negócios do PIB brasileiro\", \n    font_size = 20\n    ) |&gt; \n  reactablefmtr::add_source(\"Fonte: Fernando da Silva e CODACE.\")\n\n\nDatação de recessões - Ciclo de negócios do PIB brasileiro\n\nFonte: Fernando da Silva e CODACE.\n\n\n\n Perceba que ambas as datações são idênticas! A única diferença está na última datação, a qual o CODACE ainda não definiu o próximo vale. Dessa forma, fica demonstrado o poder e facilidade de uso do algoritmo de Harding & Pagan para datação de ciclos econômicos."
  },
  {
    "objectID": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#referências",
    "href": "blog/2021-07-20-ciclo-economico-e-datacao-de-recessoes/index.html#referências",
    "title": "Datação de ciclos econômicos e o algoritmo de Harding-Pagan",
    "section": "Referências",
    "text": "Referências\nBurns, Arthur F. & Mitchell, Wesley C., (1946). Measuring Business Cycles. National Bureau of Economic Research, Inc, https://EconPapers.repec.org/RePEc:nbr:nberbk:burn46-1.\nHarding, D., & Pagan, A. (2002). Dissecting the cycle: a methodological investigation. Journal of monetary economics, 49(2), 365-381.\n\nInformações da sessão\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 19045)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Portuguese_Brazil.utf8\n ctype    Portuguese_Brazil.utf8\n tz       America/Sao_Paulo\n date     2023-03-10\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.335 @ C:\\\\PROGRA~1\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package       * version    date (UTC) lib source\n assertthat      0.2.1      2019-03-21 [1] CRAN (R 4.2.1)\n BCDating      * 0.9.8      2019-01-07 [1] CRAN (R 4.2.0)\n cli             3.4.1      2022-09-23 [1] CRAN (R 4.2.1)\n colorspace      2.0-3      2022-02-21 [1] CRAN (R 4.2.1)\n crosstalk       1.2.0      2021-11-04 [1] CRAN (R 4.2.1)\n curl            4.3.3      2022-10-06 [1] CRAN (R 4.2.1)\n DBI             1.1.3      2022-06-18 [1] CRAN (R 4.2.1)\n digest          0.6.29     2021-12-01 [1] CRAN (R 4.2.1)\n dplyr         * 1.0.10     2022-09-01 [1] CRAN (R 4.2.1)\n ellipsis        0.3.2      2021-04-29 [1] CRAN (R 4.2.1)\n evaluate        0.17       2022-10-07 [1] CRAN (R 4.2.1)\n fansi           1.0.3      2022-03-24 [1] CRAN (R 4.2.1)\n farver          2.1.1      2022-07-06 [1] CRAN (R 4.2.1)\n fastmap         1.1.0      2021-01-25 [1] CRAN (R 4.2.1)\n generics        0.1.3      2022-07-05 [1] CRAN (R 4.2.1)\n ggbrace         0.1.0      2022-06-17 [1] Github (NicolasH2/ggbrace@51cc034)\n ggplot2       * 3.3.6      2022-05-03 [1] CRAN (R 4.2.1)\n ggtext        * 0.1.2      2022-09-16 [1] CRAN (R 4.2.1)\n ggthemes      * 4.2.4      2021-01-20 [1] CRAN (R 4.2.1)\n glue            1.6.2      2022-02-24 [1] CRAN (R 4.2.1)\n gridtext        0.1.4.9000 2022-06-07 [1] Github (wilkelab/gridtext@6192174)\n gtable          0.3.1      2022-09-01 [1] CRAN (R 4.2.1)\n htmltools       0.5.3      2022-07-18 [1] CRAN (R 4.2.1)\n htmlwidgets     1.5.4      2021-09-08 [1] CRAN (R 4.2.1)\n httr            1.4.5      2023-02-24 [1] CRAN (R 4.2.2)\n jsonlite        1.8.4      2022-12-06 [1] CRAN (R 4.2.2)\n knitr           1.40       2022-08-24 [1] CRAN (R 4.2.1)\n labeling        0.4.2      2020-10-20 [1] CRAN (R 4.2.0)\n lifecycle       1.0.3      2022-10-07 [1] CRAN (R 4.2.1)\n lubridate     * 1.9.2      2023-02-10 [1] CRAN (R 4.2.2)\n magrittr        2.0.3      2022-03-30 [1] CRAN (R 4.2.1)\n markdown        1.1        2019-08-07 [1] CRAN (R 4.2.1)\n munsell         0.5.0      2018-06-12 [1] CRAN (R 4.2.1)\n pillar          1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n pkgconfig       2.0.3      2019-09-22 [1] CRAN (R 4.2.1)\n purrr         * 0.3.5      2022-10-06 [1] CRAN (R 4.2.1)\n R6              2.5.1      2021-08-19 [1] CRAN (R 4.2.1)\n ragg            1.2.2      2022-02-21 [1] CRAN (R 4.2.1)\n Rcpp            1.0.9      2022-07-08 [1] CRAN (R 4.2.1)\n reactable     * 0.3.0      2022-05-26 [1] CRAN (R 4.2.1)\n reactablefmtr * 2.1.0      2022-08-10 [1] Github (kcuilla/reactablefmtr@8768b0a)\n reactR          0.4.4      2021-02-22 [1] CRAN (R 4.2.1)\n rjson           0.2.21     2022-01-09 [1] CRAN (R 4.2.0)\n rlang           1.0.6      2022-09-24 [1] CRAN (R 4.2.1)\n rmarkdown       2.17       2022-10-07 [1] CRAN (R 4.2.1)\n rstudioapi      0.14       2022-08-22 [1] CRAN (R 4.2.1)\n sass            0.4.2      2022-07-16 [1] CRAN (R 4.2.1)\n scales          1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n sessioninfo     1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n sidrar        * 0.2.9      2022-07-12 [1] CRAN (R 4.2.0)\n stringi         1.7.8      2022-07-11 [1] CRAN (R 4.2.1)\n stringr         1.5.0      2022-12-02 [1] CRAN (R 4.2.2)\n systemfonts     1.0.4      2022-02-11 [1] CRAN (R 4.2.1)\n textshaping     0.3.6      2021-10-13 [1] CRAN (R 4.2.1)\n tibble          3.1.8      2022-07-22 [1] CRAN (R 4.2.1)\n tidyr         * 1.2.1      2022-09-08 [1] CRAN (R 4.2.1)\n tidyselect      1.2.0      2022-10-10 [1] CRAN (R 4.2.1)\n timechange      0.2.0      2023-01-11 [1] CRAN (R 4.2.2)\n utf8            1.2.2      2021-07-24 [1] CRAN (R 4.2.1)\n vctrs           0.5.1      2022-11-16 [1] CRAN (R 4.2.1)\n withr           2.5.0      2022-03-03 [1] CRAN (R 4.2.1)\n xfun            0.33       2022-09-12 [1] CRAN (R 4.2.1)\n xml2            1.3.3      2021-11-30 [1] CRAN (R 4.2.1)\n yaml            2.3.5      2022-02-21 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/ferna/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nCompartilhar:"
  },
  {
    "objectID": "blog/2022-04-30-entendendo-cointegracao/index.html",
    "href": "blog/2022-04-30-entendendo-cointegracao/index.html",
    "title": "O andar do bêbado e seu cachorro: entendendo cointegração no R",
    "section": "",
    "text": "Muito utilizado no mercado financeiro para estratégias long-short, arbitragem estatística, pairs trading e em análise e previsão de séries temporais macroeconômicas, o conceito de cointegração é ao mesmo tempo fascinante e intimidador de se compreender. Por isso, neste breve texto iremos explicar o que é cointegração com um exemplo intuitivo e fazer um exercício simples aplicando o teste de cointegração de Engle-Granger com pares de ações brasileiras usando o R!"
  },
  {
    "objectID": "blog/2022-04-30-entendendo-cointegracao/index.html#a-analogia-do-bêbado-e-seu-cachorro",
    "href": "blog/2022-04-30-entendendo-cointegracao/index.html#a-analogia-do-bêbado-e-seu-cachorro",
    "title": "O andar do bêbado e seu cachorro: entendendo cointegração no R",
    "section": "A analogia do bêbado e seu cachorro",
    "text": "A analogia do bêbado e seu cachorro\nAs definições matemáticas de cointegração, e tópicos relacionados, são um tanto quanto sofisticadas, mas o seu conceito é simples o suficiente para ser introduzido com a cômica analogia do andar do bêbado e seu cachorro. Os créditos da analogia são inteiramente de Michael P. Murray que escreveu, em 1994, um paper didático de apenas 3 páginas elucidando o conceito de cointegração com o conto do andar do bêbado.\nImagine que você esteja andando na rua da sua cidade e aviste um bêbado que acaba de sair do bar, vagando em direção a sua casa. Você percebe que o bêbado caminha de maneira peculiar e imprevisível, algumas vezes se desviando para a esquerda e outras para a direita enquanto tenta, com dificuldades, seguir o seu caminho. Ao observar a trajetória do bêbado pode-se dizer que seus passos são nada mais do que uma sequência aleatória de passos. Na econometria, chamamos a trajetória do bêbado de passeio aleatório (random walk), de maneira a descrever o comportamento de muitas das séries econômicas que existem.\nPor andar de forma aleatória, se você desviar o olhar e parar de observar o bêbado andando, será difícil dizer onde o bêbado estará após um determinado tempo, pois sua trajetória é imprevisível. Uma das características das trajetórias do tipo passeio aleatório, como a do bêbado, é de que a melhor previsão sobre um valor futuro é o último valor observado. Dessa forma, o seu palpite sobre a localização atual do bêbado poderia ser algo como o último lugar onde você o avistou, ou seja, na saída do bar.\nAgora imagine que o bêbado tenha um cachorro amigo, sem coleira, que o acompanha. De forma similar ao bêbado, o cachorro também segue uma sequência aleatória de passos, sendo atraído por cada cheiro novo e estímulos que sente no caminho. Sempre que o bêbado percebe que o cachorro foi muito longe ele o chama: “Thor!”. E o cachorro obedece o chamado retornando para perto de seu dono, caracterizando assim uma correção da distância entre ambos.\nSe fossemos representar por meio de um gráfico a trajetória do bêbado e do cachorro ao longo do tempo e em relação a um ponto de referência qualquer (como o bar), seria algo como:\n\nObservando as trajetórias de ambos, pode-se dizer que mesmo que a localização atual do bêbado após um tempo seja imprevisível, a localização do cachorro é relativamente previsível, pois ele não se afastará muito do seu dono. Dessa forma, agora um bom palpite sobre a localização do bêbado, por exemplo, pode ser dado uma vez que você tenha encontrado o cachorro, e vice-versa, pois conforme seguem dando passos aleatórios também corrigem a distância entre ambos. Na econometria, chamamos isso formalmente de mecanismo de correção de erros.\nNote, também, que ambas as trajetórias são o que chamamos de séries temporais não-estacionárias, dado que quanto mais tempo passa é mais provável que o bêbado e seu cachorro estejam vagando bem longe de onde foram vistos por último. Se for verdade que a distância entre eles seja corrigida por um mecanismo de correção de erros, então a distância entre as trajetórias é dita cointegrada de ordem zero.\nPara entender o que a expressão cointegrada de ordem zero significa, vale primeiro entender o que são séries integradas. Séries temporais não-estacionárias que se tornam estacionárias quando diferenciadas n vezes são ditas integradas de ordem n ou, simplesmente, \\(\\text{I}(n)\\). Para duas séries temporais serem cointegradas, cada série precisa ser integrada de mesma ordem, n; por isso o termo cointegração. Sendo assim, um conjunto de séries temporais, todas integradas de ordem n, são ditas cointegradas se e somente se alguma combinação linear das séries é integrada de ordem menor do que n. Tal combinação linear foi chamada de relação de cointegração, conforme o trabalho de Engle e Granger (1987)."
  },
  {
    "objectID": "blog/2022-04-30-entendendo-cointegracao/index.html#cointegração-no-sentido-de-engle-granger",
    "href": "blog/2022-04-30-entendendo-cointegracao/index.html#cointegração-no-sentido-de-engle-granger",
    "title": "O andar do bêbado e seu cachorro: entendendo cointegração no R",
    "section": "Cointegração no sentido de Engle-Granger",
    "text": "Cointegração no sentido de Engle-Granger\nDe maneira um pouco mais formal, partindo de um modelo de passeio aleatório para as trajetórias do bêbado (\\(x_t\\)) e do cachorro (\\(y_t\\)), temos:\n\\[u_t = x_t - x_{t-1}\\] \\[w_t = y_t - y_{t-1}\\]\nonde \\(u_t\\) e \\(w_t\\) representam, respectivamente, o passeio aleatório do bêbado e do cachorro ao longo do tempo \\(t\\) e são ruído branco estacionários. Podemos então modelar a “trajetória cointegrada” do bêbado e do cachorro como:\n\\[u_t + c(y_{t-1} - x_{t-1}) = x_t - x_{t-1}\\] \\[w_t + d(x_{t-1} - y_{t-1}) = y_t - y_{t-1}\\]\nonde \\(u_t\\) e \\(w_t\\) são novamente os passeios aleatórios do bêbado e do cachorro e os termos adicionais no lado esquerdo das equações são os termos de correção de erro pelo quais o bêbado e o cachorro corrigem a distância um do outro, ou seja, permanecem próximos. Podemos então dizer que, das equações acima, \\((y_{t-1} - x_{t-1})\\) é uma relação de cointegração entre a trajetória do bêbado e do cachorro. Dessa forma, se estabelece uma relação de equilíbrio de longo prazo entre as trajetórias.\nNote que se os termos de correção de erros forem não-estacionários, então as trajetórias modeladas para o bêbado e o cachorro também seriam não-estacionárias, portanto ambos iriam provavelmente se distanciar bastante ao longo do tempo. Nesse caso, diríamos que as séries temporais das trajetórias do bêbado e do cachorro não são cointegradas de ordem zero. No entanto, Engle e Granger (1987) provaram que se a trajetória do bêbado e do cachorro são ambas integradas de ordem 1 e seguem o descrito nas equações acima, então as trajetórias cointegram.\nA analogia do bêbado e seu cachorro é uma boa forma de entender os conceitos básicos de cointegração e do mecanismo de correção de erro, no entanto, há inúmeros detalhes técnicos que devem ser considerados em aplicações com dados reais. Para se aprofundar mais no tema considere um curso de econometria de séries temporais.\nO conceito de cointegração é bastante utilizado em exercícios de macroeconomia, mas também pode ser usado no mercado financeiro com o objetivo de identificar relações — como a do bêbado e seu cachorro — entre ativos e realizar operações lucrativas com a técnica. Um exemplo disso são as estratégias de pairs trading, onde se realiza operações com pares de ativos que apresentem relação de cointegração de modo a obter lucro com a arbitragem. O grande desafio dessa aplicação é encontrar o par de ativo que apresente essas características."
  },
  {
    "objectID": "blog/2022-04-30-entendendo-cointegracao/index.html#teste-de-cointegração-de-engle-granger",
    "href": "blog/2022-04-30-entendendo-cointegracao/index.html#teste-de-cointegração-de-engle-granger",
    "title": "O andar do bêbado e seu cachorro: entendendo cointegração no R",
    "section": "Teste de Cointegração de Engle-Granger",
    "text": "Teste de Cointegração de Engle-Granger\nDe maneira prática, para verificar se um conjunto de séries temporais \\(y_t\\) e \\(x_t\\) cointegram, é preciso seguir os procedimentos propostos por Engle e Granger (1987):\n\nVerificar se as séries são estacionárias;\nEstimar a regressão cointegrante das séries: \\(y_t = \\alpha + \\beta x_t + \\epsilon_t\\);\nVerificar se o resíduo da regressão cointegrante é estacionário usando os valores críticos de Engle e Granger (1987);\nSe o resíduo for estacionário, a regressão cointegrante não é espúria e pode-se estimar um modelo de correção de erros para obter a relação de equilíbrio das séries.\n\nA seguir mostraremos como aplicar o teste com um par de ações negociadas na B3 e para isso usaremos a linguagem R."
  },
  {
    "objectID": "blog/2022-04-30-entendendo-cointegracao/index.html#exemplo-no-r",
    "href": "blog/2022-04-30-entendendo-cointegracao/index.html#exemplo-no-r",
    "title": "O andar do bêbado e seu cachorro: entendendo cointegração no R",
    "section": "Exemplo no R",
    "text": "Exemplo no R\nO exemplo utilizará o par de ações PETR3 e PETR4 no período de 28 de março de 2021 até 28 de março de 2022. Os dados são públicos e podem ser acessados pelo Yahoo Finance, havendo opção de usar pacotes ou web scraping para extrair os dados. O código abaixo faz a extração e tratamento de dados:\n\nCode# Carregar pacotes\nlibrary(httr2)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggtext)\nlibrary(aTSA)\n\n\n# Função para importar arquivo CSV do Yahoo Finance como um tibble\nread_yfinance &lt;- function(url) {\n  pagina &lt;- httr2::request(base_url = url)\n  conteudo &lt;- pagina |&gt; httr2::req_perform() |&gt; httr2::resp_body_string()\n  tabela &lt;- readr::read_csv(file = conteudo)\n  return(tabela)\n}\n\n\n# Coleta de dados online: ações da PETR3 e PETR4\ndados_petr3 &lt;- read_yfinance(\n  paste0(\n    \"https://query1.finance.yahoo.com/v7/finance/download/PETR3.SA?period1=\",\n    \"1619568000&period2=1651104000&interval=1d&events=history&includeAdjust\",\n    \"edClose=true\"\n    )\n  )\ndados_petr4 &lt;- read_yfinance(\n  paste0(\n    \"https://query1.finance.yahoo.com/v7/finance/download/PETR4.SA?period1=\",\n    \"1619568000&period2=1651104000&interval=1d&events=history&includeAdjust\",\n    \"edClose=true\"\n    )\n  )\n\n# Cruzamento e tratamento dde dados\ndados &lt;- dplyr::left_join(\n  x  = dplyr::select(dados_petr3, \"date\" = \"Date\", \"PETR3\" = \"Adj Close\"),\n  y  = dplyr::select(dados_petr4, \"date\" = \"Date\", \"PETR4\" = \"Adj Close\"),\n  by = \"date\"\n  )\n\n\nAntes de partir para o teste vale visualizar as séries temporais:\n\nCode# Plotar séries\ndados_long &lt;- dados |&gt; \n  tidyr::pivot_longer(cols = -\"date\")\n\nggplot2::ggplot(data = dados_long) +\n  ggplot2::aes(x = date, y = value, color = name) +\n  ggplot2::geom_line(size = 1) +\n  ggplot2::scale_x_date(date_breaks = \"2 months\", date_labels = \"%b/%Y\") +\n  ggplot2::scale_y_continuous(n.breaks = 6) +\n  ggplot2::scale_color_manual(values = c(\"#282f6b\", \"#b22200\")) +\n  ggplot2::labs(\n    title   = \"Preço de fechamento diário ajustado\",\n    x       = NULL,\n    y       = NULL,\n    color   = NULL,\n    caption = \"**Dados**: Yahoo Finance | **Elaboração**: Fernando da Silva\"\n    ) + \n  ggplot2::theme_light(base_size = 16) +\n  ggplot2::theme(\n    plot.title   = ggplot2::element_text(face = \"bold\"),\n    plot.caption = ggtext::element_textbox_simple(\n      margin = ggplot2::margin(10, 0, 0, 0)\n      ),\n    plot.title.position   = \"plot\",\n    plot.caption.position = \"plot\",\n    legend.text           = ggplot2::element_text(face = \"bold\"),\n    legend.position       = c(0.1, 0.85),\n    legend.key            = ggplot2::element_blank(),\n    legend.background     = ggplot2::element_blank()\n    )\n\n\n\n\nAs séries parecem apresentar uma trajetória de passeio aleatório, como a do bêbado e seu cachorro, algo comum em séries de ativos financeiros.\nAgora vamos para a primeira etada do teste de cointegração de Engle-Granger, ou seja, verificar se as séries são estacionárias. Podemos fazer isso com o teste ADF através da função adf.test():\n\n\n\nCodeaTSA::adf.test(dados$PETR3)\n\nAugmented Dickey-Fuller Test \nalternative: stationary \n \nType 1: no drift no trend \n     lag  ADF p.value\n[1,]   0 1.41   0.959\n[2,]   1 1.52   0.967\n[3,]   2 1.64   0.975\n[4,]   3 1.61   0.974\n[5,]   4 1.84   0.983\nType 2: with drift no trend \n     lag    ADF p.value\n[1,]   0 -0.982   0.703\n[2,]   1 -1.014   0.692\n[3,]   2 -0.969   0.707\n[4,]   3 -1.007   0.694\n[5,]   4 -0.997   0.698\nType 3: with drift and trend \n     lag   ADF p.value\n[1,]   0 -2.42   0.401\n[2,]   1 -2.30   0.447\n[3,]   2 -2.15   0.512\n[4,]   3 -2.18   0.501\n[5,]   4 -2.00   0.576\n---- \nNote: in fact, p.value = 0.01 means p.value &lt;= 0.01 \n\n\n\n\n\nCodeaTSA::adf.test(dados$PETR4)\n\nAugmented Dickey-Fuller Test \nalternative: stationary \n \nType 1: no drift no trend \n     lag  ADF p.value\n[1,]   0 1.18   0.937\n[2,]   1 1.24   0.945\n[3,]   2 1.29   0.951\n[4,]   3 1.36   0.956\n[5,]   4 1.56   0.970\nType 2: with drift no trend \n     lag   ADF p.value\n[1,]   0 -1.17   0.637\n[2,]   1 -1.20   0.627\n[3,]   2 -1.17   0.636\n[4,]   3 -1.18   0.635\n[5,]   4 -1.18   0.634\nType 3: with drift and trend \n     lag   ADF p.value\n[1,]   0 -2.68   0.290\n[2,]   1 -2.62   0.315\n[3,]   2 -2.54   0.349\n[4,]   3 -2.46   0.383\n[5,]   4 -2.28   0.456\n---- \nNote: in fact, p.value = 0.01 means p.value &lt;= 0.01 \n\n\n\n\nConforme os resultados, falhamos em rejeitar a hipótese nula do teste de a série ter raiz unitária, ou seja, as séries são não-estacionárias nos testes considerados (sem constante com tendência, com constante sem tendência e com constante e tendência).\nIdentificado que as séries são integradas de mesma ordem (nesse caso I(1), conforme pode ser confirmado usando a função forecast::ndiffs), podemos prosseguir com as etapas 2 e 3 que envolvem estimar a regressão cointegrante e verificar a estacionariedade do resíduo desta regressão. No R, isso tudo pode ser feito com a função coint.test(), que já toma o cuidado de usar os valores críticos corretos para testar os resíduos, conforme MacKinnon (1991).\n\nCode# Teste de Cointegração de Engle-Granger\naTSA::coint.test(dados$PETR3, dados$PETR4)\n\nResponse: dados$PETR3 \nInput: dados$PETR4 \nNumber of inputs: 1 \nModel: y ~ X + 1 \n------------------------------- \nEngle-Granger Cointegration Test \nalternative: cointegrated \n\nType 1: no trend \n    lag      EG p.value \n   4.00   -4.25    0.01 \n----- \n Type 2: linear trend \n    lag      EG p.value \n  4.000   0.437   0.100 \n----- \n Type 3: quadratic trend \n    lag      EG p.value \n  4.000   0.364   0.100 \n----------- \nNote: p.value = 0.01 means p.value &lt;= 0.01 \n    : p.value = 0.10 means p.value &gt;= 0.10 \n\n\nNote que a função aplica 3 especificações: sem tendência, com tendência e com tendência quadrática. Em outros pacotes estatísticos e econométricos, como no Gretl, considera-se geralmente somente a primeira. Conforme os resultados, pelo p-valor da primeira especificação, sem tendência, temos que o resíduo da regressão cointegrante é estacionário, mas isso não se verifica para outras especificações. Em outras palavras, há evidências de que as séries PETR3 e PETR4 cointegram, para a amostra de dados selecionada e com base no teste sobre o resíduo sem tendência (se o resíduo apresentar tendência, outro tipo do teste deve ser considerado)."
  },
  {
    "objectID": "blog/2022-04-30-entendendo-cointegracao/index.html#referências",
    "href": "blog/2022-04-30-entendendo-cointegracao/index.html#referências",
    "title": "O andar do bêbado e seu cachorro: entendendo cointegração no R",
    "section": "Referências",
    "text": "Referências\nAbordamos brevemente o conceito de cointegração de séries temporais no sentido de Engle-Granger. Há vários buracos deixados ao longo do texto que precisam de mais espaço e conhecimentos prévios para serem preenchidos. Espero poder abordar outros desses tópicos sobre séries temporais adiante, mas por enquanto aproveite para conferir abaixo os trabalhos citados.\nEngle, R. F., & Granger, C. W. (1987). Co-integration and error correction: representation, estimation, and testing. Econometrica: journal of the Econometric Society, 251-276.\nMacKinnon, J. G. (1991). Critical values for cointegration tests, Ch. 13 in Long-run Economic Relationships: Readings in Cointegration, eds. R. F. Engle and C. W. J. Granger, Oxford, Oxford University Press.\nMurray, M. P. (1994). A drunk and her dog: an illustration of cointegration and error correction. The American Statistician, 48(1), 37-39.\n\nInformações da sessão\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 19045)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Portuguese_Brazil.utf8\n ctype    Portuguese_Brazil.utf8\n tz       America/Sao_Paulo\n date     2023-03-10\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   1.2.335 @ C:\\\\PROGRA~1\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version    date (UTC) lib source\n D archive       1.1.5      2022-05-06 [1] CRAN (R 4.2.2)\n   assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.1)\n   aTSA        * 3.1.2      2015-07-08 [1] CRAN (R 4.2.0)\n   bit           4.0.4      2020-08-04 [1] CRAN (R 4.2.1)\n   bit64         4.0.5      2020-08-30 [1] CRAN (R 4.2.1)\n   cli           3.4.1      2022-09-23 [1] CRAN (R 4.2.1)\n   colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.1)\n   crayon        1.5.2      2022-09-29 [1] CRAN (R 4.2.1)\n   curl          4.3.3      2022-10-06 [1] CRAN (R 4.2.1)\n   DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.1)\n   digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.1)\n   dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.1)\n   ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.1)\n   evaluate      0.17       2022-10-07 [1] CRAN (R 4.2.1)\n   fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.1)\n   farver        2.1.1      2022-07-06 [1] CRAN (R 4.2.1)\n   fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.1)\n   generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.1)\n   ggplot2     * 3.3.6      2022-05-03 [1] CRAN (R 4.2.1)\n   ggtext      * 0.1.2      2022-09-16 [1] CRAN (R 4.2.1)\n   glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.1)\n   gridtext      0.1.4.9000 2022-06-07 [1] Github (wilkelab/gridtext@6192174)\n   gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.1)\n   hms           1.1.2      2022-08-19 [1] CRAN (R 4.2.1)\n   htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.1)\n   htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.1)\n   httr2       * 0.2.2      2022-09-25 [1] CRAN (R 4.2.1)\n   jsonlite      1.8.4      2022-12-06 [1] CRAN (R 4.2.2)\n   knitr         1.40       2022-08-24 [1] CRAN (R 4.2.1)\n   labeling      0.4.2      2020-10-20 [1] CRAN (R 4.2.0)\n   lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.1)\n   magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.1)\n   markdown      1.1        2019-08-07 [1] CRAN (R 4.2.1)\n   munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.1)\n   pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n   pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.1)\n   purrr         0.3.5      2022-10-06 [1] CRAN (R 4.2.1)\n   R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.1)\n   rappdirs      0.3.3      2021-01-31 [1] CRAN (R 4.2.1)\n   Rcpp          1.0.9      2022-07-08 [1] CRAN (R 4.2.1)\n   readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.1)\n   rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.1)\n   rmarkdown     2.17       2022-10-07 [1] CRAN (R 4.2.1)\n   rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.1)\n   scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n   sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n   stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.1)\n   stringr       1.5.0      2022-12-02 [1] CRAN (R 4.2.2)\n   tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.1)\n   tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.1)\n   tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.1)\n   tzdb          0.3.0      2022-03-28 [1] CRAN (R 4.2.1)\n   utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.1)\n   vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.1)\n   vroom         1.6.0      2022-09-30 [1] CRAN (R 4.2.1)\n   withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.1)\n   xfun          0.33       2022-09-12 [1] CRAN (R 4.2.1)\n   xml2          1.3.3      2021-11-30 [1] CRAN (R 4.2.1)\n   yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/ferna/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n D ── DLL MD5 mismatch, broken installation.\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nCompartilhar:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fernando da Silva",
    "section": "",
    "text": "English  Português\n\n\n\nI’m a data scientist specialized in economics and finance. I try to solve real world problems with simple models.\nIn college, where I studied economics, I founded GECE/FURG to analyze data and discovered my vocation there. Today I work at Análise Macro focused on time series analysis, econometrics, and machine learning applications, aiming to explain and predict the behavior of economic variables, allowing data-based decisions. My work has already helped over 2000 students.\nMy main skills in my portfolio are predictive models; time series; data analysis and visualization; data products such as reports and dashboards; and technologies such as R, Python, Git, GitHub, and SQL.\nI love constantly learning new things, sharing knowledge openly and interacting with people on these topics.\n\n\nSou um cientista de dados especializado em economia e finanças. Eu procuro solucionar problemas do mundo real com modelos simples.\nNa graduação, onde estudei economia, fundei o GECE/FURG para analisar dados e descobri aí a minha vocação. Hoje trabalho na Análise Macro focado em aplicações de análise de séries temporais, econometria e machine learning, visando explicar e prever o comportamento de variáveis econômicas, permitindo decisões baseadas em dados. Meu trabalho já ajudou mais de 2000 estudantes.\nMinhas principais habilidades em meu portfólio são modelos de previsão; séries temporais; análise e visualização de dados; produtos de dados como relatórios e dashboards; e tecnologias como R, Python, Git, GitHub e SQL.\nEu adoro constantemente aprender coisas novas, compartilhar conhecimento de forma aberta e interagir com pessoas sobre estes tópicos."
  }
]